#!/usr/bin/env python3
"""
å¹¶è¡ŒBAGELç›¸ä¼¼æ€§è®¡ç®—å™¨ - å……åˆ†åˆ©ç”¨å¤šGPUèµ„æº
"""

import os
import json
import time
import logging
import multiprocessing as mp
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from pathlib import Path
from PIL import Image
import torch

from .calculator import BagelSimilarityCalculator
from .config import BagelSimilarityConfig
from .utils import load_image, export_batch_results

logger = logging.getLogger(__name__)


class GPUWorker:
    """å•GPUå·¥ä½œè¿›ç¨‹"""
    
    def __init__(self, gpu_id: int, config: BagelSimilarityConfig):
        self.gpu_id = gpu_id
        self.config = config
        self.calculator = None
        
    def initialize(self):
        """åˆå§‹åŒ–GPUå·¥ä½œå™¨"""
        try:
            # è®¾ç½®GPUè®¾å¤‡
            os.environ['CUDA_VISIBLE_DEVICES'] = str(self.gpu_id)
            
            # ä¿®æ”¹é…ç½®ä»¥ä½¿ç”¨å•GPU
            single_gpu_config = self.config
            single_gpu_config.model.max_memory = {0: "22GiB", "cpu": "32GiB"}
            single_gpu_config.model.device_map = "auto"
            
            # åˆå§‹åŒ–è®¡ç®—å™¨
            self.calculator = BagelSimilarityCalculator(single_gpu_config)
            logger.info(f"GPU {self.gpu_id} worker initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize GPU {self.gpu_id} worker: {e}")
            return False
    
    def process_image(self, image_path: str, prompt: str) -> Dict[str, Any]:
        """å¤„ç†å•å¼ å›¾åƒ"""
        try:
            start_time = time.time()
            
            # è®¡ç®—ç›¸ä¼¼æ€§åˆ†æ•°
            results = self.calculator.calculate_all_scores(image_path, prompt)
            
            # æ·»åŠ GPUä¿¡æ¯å’Œå¤„ç†æ—¶é—´
            results['gpu_id'] = self.gpu_id
            results['calculation_time'] = time.time() - start_time
            
            logger.info(f"GPU {self.gpu_id} processed {os.path.basename(image_path)} in {results['calculation_time']:.2f}s")
            return results
            
        except Exception as e:
            logger.error(f"GPU {self.gpu_id} failed to process {image_path}: {e}")
            return {
                'image_path': image_path,
                'gpu_id': self.gpu_id,
                'error': str(e),
                'calculation_time': time.time() - start_time if 'start_time' in locals() else 0
            }


def gpu_worker_process(gpu_id: int, config_dict: Dict, task_queue: mp.Queue, result_queue: mp.Queue):
    """GPUå·¥ä½œè¿›ç¨‹å‡½æ•°"""
    try:
        # é‡å»ºé…ç½®å¯¹è±¡
        config = BagelSimilarityConfig.from_dict(config_dict)
        
        # åˆ›å»ºå¹¶åˆå§‹åŒ–å·¥ä½œå™¨
        worker = GPUWorker(gpu_id, config)
        if not worker.initialize():
            result_queue.put(('error', f'Failed to initialize GPU {gpu_id}'))
            return
        
        result_queue.put(('ready', f'GPU {gpu_id} ready'))
        
        # å¤„ç†ä»»åŠ¡
        while True:
            try:
                task = task_queue.get(timeout=5)
                if task is None:  # ç»“æŸä¿¡å·
                    break
                    
                image_path, prompt = task
                result = worker.process_image(image_path, prompt)
                result_queue.put(('result', result))
                
            except Exception as e:
                logger.error(f"GPU {gpu_id} worker error: {e}")
                result_queue.put(('error', f'GPU {gpu_id} error: {str(e)}'))
                
    except Exception as e:
        logger.error(f"GPU {gpu_id} process failed: {e}")
        result_queue.put(('error', f'GPU {gpu_id} process failed: {str(e)}'))


class ParallelBagelCalculator:
    """å¹¶è¡ŒBAGELç›¸ä¼¼æ€§è®¡ç®—å™¨"""
    
    def __init__(self, config: BagelSimilarityConfig):
        self.config = config
        self.gpu_count = torch.cuda.device_count()
        self.processes = []
        self.task_queue = None
        self.result_queue = None
        
        logger.info(f"Initializing parallel calculator with {self.gpu_count} GPUs")
        
    def _start_workers(self):
        """å¯åŠ¨GPUå·¥ä½œè¿›ç¨‹"""
        try:
            # åˆ›å»ºé˜Ÿåˆ—
            self.task_queue = mp.Queue()
            self.result_queue = mp.Queue()
            
            # å¯åŠ¨å·¥ä½œè¿›ç¨‹
            for gpu_id in range(self.gpu_count):
                config_dict = self.config.to_dict()
                process = mp.Process(
                    target=gpu_worker_process,
                    args=(gpu_id, config_dict, self.task_queue, self.result_queue)
                )
                process.start()
                self.processes.append(process)
                logger.info(f"Started worker process for GPU {gpu_id}")
            
            # ç­‰å¾…æ‰€æœ‰GPUå°±ç»ª
            ready_count = 0
            while ready_count < self.gpu_count:
                try:
                    msg_type, msg_data = self.result_queue.get(timeout=60)
                    if msg_type == 'ready':
                        ready_count += 1
                        logger.info(msg_data)
                    elif msg_type == 'error':
                        logger.error(msg_data)
                        raise RuntimeError(f"GPU initialization failed: {msg_data}")
                except Exception as e:
                    logger.error(f"Failed to start workers: {e}")
                    self.shutdown()
                    raise
                    
            logger.info(f"All {self.gpu_count} GPU workers are ready")
            
        except Exception as e:
            logger.error(f"Failed to start workers: {e}")
            self.shutdown()
            raise
    
    def process_batch_parallel(self, image_paths: List[str], prompt: str, 
                             checkpoint_interval: int = 100) -> List[Dict[str, Any]]:
        """å¹¶è¡Œå¤„ç†æ‰¹é‡å›¾åƒ"""
        try:
            # å¯åŠ¨å·¥ä½œè¿›ç¨‹
            self._start_workers()
            
            total_images = len(image_paths)
            results = []
            processed_count = 0
            
            logger.info(f"Starting parallel processing of {total_images} images")
            logger.info(f"Checkpoint interval: every {checkpoint_interval} images")
            
            # åˆ†å‘ä»»åŠ¡
            for image_path in image_paths:
                self.task_queue.put((image_path, prompt))
            
            # æ”¶é›†ç»“æœ
            while processed_count < total_images:
                try:
                    msg_type, msg_data = self.result_queue.get(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                    
                    if msg_type == 'result':
                        results.append(msg_data)
                        processed_count += 1
                        
                        # æ‰“å°è¿›åº¦
                        if processed_count % 10 == 0 or processed_count == total_images:
                            logger.info(f"Progress: {processed_count}/{total_images} images processed")
                        
                        # å®šæœŸå­˜æ¡£
                        if processed_count % checkpoint_interval == 0:
                            self._save_checkpoint(results, processed_count)
                            
                    elif msg_type == 'error':
                        logger.error(f"Worker error: {msg_data}")
                        
                except Exception as e:
                    logger.error(f"Error collecting results: {e}")
                    break
            
            # æœ€ç»ˆå­˜æ¡£
            if results:
                self._save_checkpoint(results, processed_count, final=True)
            
            logger.info(f"Parallel processing completed: {processed_count}/{total_images} images")
            return results
            
        except Exception as e:
            logger.error(f"Parallel processing failed: {e}")
            raise
        finally:
            self.shutdown()
    
    def _save_checkpoint(self, results: List[Dict[str, Any]], count: int, final: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            checkpoint_type = "final" if final else "checkpoint"
            
            # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
            checkpoint_dir = f"bs_cal/checkpoints_{timestamp}"
            os.makedirs(checkpoint_dir, exist_ok=True)
            
            # ä¿å­˜ç»“æœ
            checkpoint_file = os.path.join(checkpoint_dir, f"{checkpoint_type}_{count}_results.json")
            with open(checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'timestamp': timestamp,
                    'processed_count': count,
                    'checkpoint_type': checkpoint_type,
                    'results': results
                }, f, indent=2, ensure_ascii=False)
            
            # å¯¼å‡ºåˆ†ææ–‡ä»¶
            if final or count % 500 == 0:  # æ¯500ä¸ªæˆ–æœ€ç»ˆç»“æœå¯¼å‡ºåˆ†ææ–‡ä»¶
                export_batch_results(results, checkpoint_dir)
            
            logger.info(f"ğŸ’¾ Checkpoint saved: {checkpoint_file} ({count} images)")
            print(f"ğŸ’¾ Checkpoint saved: {count} images processed")
            
        except Exception as e:
            logger.error(f"Failed to save checkpoint: {e}")
    
    def shutdown(self):
        """å…³é—­å¹¶è¡Œè®¡ç®—å™¨"""
        try:
            # å‘é€ç»“æŸä¿¡å·
            if self.task_queue:
                for _ in range(self.gpu_count):
                    self.task_queue.put(None)
            
            # ç­‰å¾…è¿›ç¨‹ç»“æŸ
            for process in self.processes:
                if process.is_alive():
                    process.join(timeout=10)
                    if process.is_alive():
                        process.terminate()
                        process.join()
            
            logger.info("All GPU workers shut down successfully")
            
        except Exception as e:
            logger.error(f"Error during shutdown: {e}")
        finally:
            self.processes = []
            self.task_queue = None
            self.result_queue = None


def test_parallel_calculator():
    """æµ‹è¯•å¹¶è¡Œè®¡ç®—å™¨"""
    from .config import BagelSimilarityConfig
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = BagelSimilarityConfig()
    
    # åˆ›å»ºå¹¶è¡Œè®¡ç®—å™¨
    parallel_calc = ParallelBagelCalculator(config)
    
    # æµ‹è¯•å›¾åƒè·¯å¾„
    test_images = [
        "data_1000/classic_0001.jpg",
        "data_1000/classic_0002.jpg", 
        "data_1000/classic_0003.jpg"
    ]
    
    try:
        # å¹¶è¡Œå¤„ç†
        results = parallel_calc.process_batch_parallel(
            test_images, 
            "Please describe this image in detail",
            checkpoint_interval=2
        )
        
        print(f"âœ… Parallel processing completed: {len(results)} results")
        for result in results:
            print(f"  GPU {result.get('gpu_id', 'unknown')}: {os.path.basename(result.get('image_path', 'unknown'))}")
            
    except Exception as e:
        print(f"âŒ Parallel processing failed: {e}")
    finally:
        parallel_calc.shutdown()


if __name__ == "__main__":
    test_parallel_calculator()
